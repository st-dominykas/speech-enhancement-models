{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa as lr\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from generator import Generator\n",
    "\n",
    "from torchmetrics.audio.pesq import PerceptualEvaluationSpeechQuality\n",
    "from torchmetrics.functional.audio.stoi import short_time_objective_intelligibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "generator.load_state_dict(torch.load('./SEGAN_generator_weights.pkl',map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssim(signal_1, signal_2):\n",
    "    mu_1 = signal_1.mean()\n",
    "    mu_2 = signal_2.mean()\n",
    "    var_1 = signal_1.var()\n",
    "    var_2 = signal_2.var()\n",
    "    cov_1_2 = np.cov([signal_1, signal_2])[1][0]\n",
    "    L = abs(max(max(signal_1),max(signal_2)) -min(min(signal_1),min(signal_2)))\n",
    "    k_1 = 0.01\n",
    "    k_2 = 0.03\n",
    "    c_1 = (k_1 * L)**2\n",
    "    c_2 = (k_2 * L)**2\n",
    "\n",
    "    l = (2*mu_1*mu_2 + c_1)/(mu_1**2 + mu_2**2 + c_1)\n",
    "    c = (2*(var_1**(1/2))*(var_2**(1/2)) + c_2)/(var_1 + var_2 + c_2)\n",
    "    s = (cov_1_2 + c_2/2)/((var_1**(1/2))*(var_2**(1/2))+c_2/2)\n",
    "\n",
    "    return l*c*s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(clean_path, noisy_path):\n",
    "    # cut signal into frames of length, pass them to model and glue it back\n",
    "    clean_signal, _ = torchaudio.load(clean_path)\n",
    "    if _ != 16000:\n",
    "        clean_signal = torchaudio.transforms.Resample(_,16000)(clean_signal).flatten()\n",
    "    else:\n",
    "        clean_signal = clean_signal.flatten()\n",
    "    noisy_signal, _ = torchaudio.load(noisy_path)\n",
    "    if _ != 16000:\n",
    "        noisy_signal = torchaudio.transforms.Resample(_,16000)(noisy_signal).flatten()\n",
    "\n",
    "    # pad signal with zeros to have full frames to cut\n",
    "    pad_size = (noisy_signal.shape[0]//2**14 + 1)*(2**14) - noisy_signal.shape[0]\n",
    "    noisy_padded = F.pad(input=noisy_signal, pad=(0,pad_size), mode='constant', value=0)\n",
    "\n",
    "    z = nn.init.normal_(torch.Tensor(1, 1024, 8))\n",
    "\n",
    "    # crop signal and process it piece by piece\n",
    "    denoised_signal = torch.tensor([])\n",
    "    for frame in np.arange(0, (noisy_padded.shape[0]//2**14)*(2**14), step = 2**14):\n",
    "        if denoised_signal.shape[0]==0:\n",
    "            denoised_signal = generator(noisy_padded[frame:frame+2**14].unsqueeze(0).unsqueeze(0), z)[0][0]\n",
    "        else:\n",
    "            denoised_signal = torch.cat((denoised_signal,generator(noisy_padded[frame:frame+2**14].unsqueeze(0).unsqueeze(0), z)[0][0]))\n",
    "\n",
    "    denoised_signal = denoised_signal[:noisy_signal.shape[0]]   \n",
    "\n",
    "\n",
    "    # PESQ\n",
    "    wb_pesq = PerceptualEvaluationSpeechQuality(16000, 'wb')\n",
    "    interim_denoised_pesq = wb_pesq(denoised_signal, clean_signal)\n",
    "\n",
    "    # STOI\n",
    "    denoised_stoi = short_time_objective_intelligibility(denoised_signal, clean_signal, 16000)\n",
    "\n",
    "    # SSIM\n",
    "    denoised_ssim = ssim(clean_signal.detach().numpy(), denoised_signal.detach().numpy())\n",
    "    \n",
    "    return [interim_denoised_pesq.item(), \n",
    "            denoised_stoi.item(), \n",
    "            denoised_ssim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_path = ''\n",
    "clean_path = ''\n",
    "pesq, stoi, ssim = calculate_metrics(clean_path, noisy_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10570769181f3bef521e17ca461192a1c83fd1537522c84236007b668e38ca34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
